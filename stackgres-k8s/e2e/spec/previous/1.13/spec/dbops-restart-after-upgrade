#!/bin/sh

. "$SPEC_PATH/abstract/metrics"

e2e_test_extra_hash() {
  "$SHELL" "$PROJECT_PATH/stackgres-k8s/ci/build/build-functions.sh" path_hash \
    "$(realpath --relative-to "$PROJECT_PATH" "$SPEC_PATH/abstract/metrics")"
}

e2e_exclusive_lock() {
  true
}

e2e_test_install() {
  if ! can_install_operator_version "$STACKGRES_PREVIOUS_VERSION"
  then
    return
  fi

  CLUSTER_CRD="sgclusters.stackgres.io"

  RANDOM_VALUE="$(random_string)"
  CLUSTER_1_NAME="$(get_sgcluster_name "$CLUSTER_NAME-1")"
  DBOPS_1_NAME="$(get_sgdbops_name "restart-1")"

  PREVIOUS_PATRONI_IMAGE="$(get_component_images "$STACKGRES_PREVIOUS_VERSION")"
  PREVIOUS_PATRONI_IMAGE="$(printf '%s' "$PREVIOUS_PATRONI_IMAGE" | grep '/patroni\(-ext\)\?:v[0-9.]\+-pg')"
  PREVIOUS_PATRONI_IMAGE="$(printf '%s' "$PREVIOUS_PATRONI_IMAGE" | tail -n 1)"
  PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION_WITH_BUILD_VERSION="${PREVIOUS_PATRONI_IMAGE##*-pg}"
  PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION="${PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION_WITH_BUILD_VERSION%%-build-*}"
  PREVIOUS_PATRONI_IMAGE_POSTGRES_MAJOR_VERSION="${PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION_WITH_BUILD_VERSION%%.*}"
  PATRONI_IMAGE="$(get_component_images "$STACKGRES_PREVIOUS_VERSION" | grep '/patroni\(-ext\)\?:v[0-9.]\+-pg'"$PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION-")"
  PATRONI_IMAGE="$(printf '%s' "$PATRONI_IMAGE" | tail -n 1)"

  k8s_unnamespaced_cleanup
  k8s_cleanup_namespace "$OPERATOR_NAMESPACE"
  k8s_async_cleanup

  if [ "$E2E_FORCE_IMAGE_PULL" = "true" ] \
    && [ "$E2E_UPGRADE_SKIP_IMAGE_PULL" != true ]
  then
    if [ "$E2E_SKIP_LOAD_OPERATOR" != true ]
    then
      load_operator_images_from "$E2E_OPERATOR_REGISTRY" "$E2E_OPERATOR_REGISTRY_PATH" \
        "$STACKGRES_PREVIOUS_VERSION"
    fi

    if [ "$E2E_SKIP_LOAD_COMPONENTS" != true ]
    then
      E2E_INCLUDE_ONLY_POSTGRES_VERSIONS= load_component_images_from "$E2E_COMPONENTS_REGISTRY" "$E2E_COMPONENTS_REGISTRY_PATH" \
        "$STACKGRES_PREVIOUS_VERSION"
    fi

    if [ "$E2E_SKIP_LOAD_EXTENSIONS" != true ]
    then
      load_extensions_images_from "$E2E_EXTENSIONS_REGISTRY" "$E2E_EXTENSIONS_REGISTRY_PATH" \
        "$STACKGRES_PREVIOUS_VERSION"
    fi
  fi

  PREVIOUS_VERSION_AS_NUMBER="$(get_version_as_number "$STACKGRES_PREVIOUS_VERSION")"
  VERSION_AS_NUMBER_0_9_5="$(get_version_as_number 0.9.5)"
  VERSION_AS_NUMBER_1_3_3="$(get_version_as_number 1.3.3)"
  if [ "$PREVIOUS_VERSION_AS_NUMBER" -gt "$VERSION_AS_NUMBER_1_3_3" ]
  then
    install_prometheus_operator
  elif [ "$PREVIOUS_VERSION_AS_NUMBER" -gt "$VERSION_AS_NUMBER_0_9_5" ]
  then
    E2E_GRAFANA_VERSION=8.5.13 install_prometheus_operator
  else
    E2E_GRAFANA_VERSION=8.5.13 install_prometheus_operator_for_version 12.8.0
  fi
  install_operator_previous_version \
    --set grafana.autoEmbed=true \
    --set-string grafana.webHost="prometheus-grafana.$(prometheus_namespace)"

  kubectl create namespace "$CLUSTER_NAMESPACE"

  install_minio

  DISTRIBUTEDLOGS_NAME="$(get_sgdistributedlogs_name distributedlogs)"
  create_or_replace_cluster_for_version "$STACKGRES_PREVIOUS_VERSION" "$CLUSTER_NAME" "$CLUSTER_NAMESPACE" 1 \
    --set cluster.create=false \
    --set-string cluster.postgres.version="$PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION" \
    --set instanceProfiles[0].name=size-s \
    --set instanceProfiles[0].cpu=125m \
    --set instanceProfiles[0].memory=512Mi \
    --set configurations.objectstorage.create=true \
    --set-string cluster.configurations.backups.sgObjectStorage=backupconf \
    --set-string cluster.configurations.backups.cronSchedule='0 5 31 2 *' \
    --set cluster.configurations.backups.performance.maxDiskBandwidth=10485760 \
    --set cluster.configurations.backups.performance.maxNetworkBandwidth=5242880 \
    --set-string configurations.postgresconfig.postgresql\\.conf.max_connections=100 \
    --set-string configurations.postgresconfig.postgresql\\.conf.invalid_param=true \
    --set distributedLogs.enabled=true \
    --set distributedLogs.create=true \
    --set-string cluster.distributedLogs.sgDistributedLogs="$DISTRIBUTEDLOGS_NAME" \
    --set-string distributedLogs.persistentVolume.size=128Mi

  create_or_replace_cluster_for_version "$STACKGRES_PREVIOUS_VERSION" \
    "$CLUSTER_1_NAME" "$CLUSTER_NAMESPACE" 1 \
    --set configurations.create=false --set instanceProfiles=false \
    --set-string cluster.sgInstanceProfile=size-s \
    --set-string cluster.postgres.version="$PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION" \
    --set cluster.configurations.observability.prometheusAutobind=true \
    --set configurations.objectstorage.create=false \
    --set-string cluster.configurations.backups.sgObjectStorage=backupconf \
    --set-string cluster.configurations.backups.cronSchedule='0 5 31 2 *' \
    --set cluster.configurations.backups.performance.maxDiskBandwidth=10485760 \
    --set cluster.configurations.backups.performance.maxNetworkBandwidth=5242880 \
    --set distributedLogs.enabled=true \
    --set distributedLogs.create=false \
    --set-string cluster.distributedLogs.sgDistributedLogs="$CLUSTER_NAMESPACE.$DISTRIBUTEDLOGS_NAME"

  deploy_curl_pod "$CLUSTER_NAMESPACE"

  wait_pods_running "$CLUSTER_NAMESPACE" 1 "$CLUSTER_1_NAME-[0-9]\+"

  BACKUP_NAME="$(get_sgbackup_name "$CLUSTER_NAME-backup-1")"

  cat << EOF | kubectl create -f -
apiVersion: stackgres.io/$(kubectl get crd sgbackups.stackgres.io --template '{{ (index .spec.versions 0).name }}')
kind: SGBackup
metadata:
  namespace: "$CLUSTER_NAMESPACE"
  name: "$BACKUP_NAME"
spec:
  sgCluster: "$CLUSTER_1_NAME"
  managedLifecycle: false
EOF
  
  wait_until e2e_is_backup_phase "Completed"

  remove_cluster "$CLUSTER_1_NAME" "$CLUSTER_NAMESPACE"
  kubectl create secret generic -n "$CLUSTER_NAMESPACE" secret-script \
    --from-literal=script="CREATE DATABASE secret_managed_sql;"
  kubectl create configmap -n "$CLUSTER_NAMESPACE" configmap-script \
    --from-literal=script="CREATE DATABASE configmap_managed_sql;"
  create_or_replace_cluster_for_version "$STACKGRES_PREVIOUS_VERSION" \
    "$CLUSTER_1_NAME" "$CLUSTER_NAMESPACE" 1 \
    --set configurations.create=false --set instanceProfiles=false \
    --set-string cluster.sgInstanceProfile=size-s \
    --set-string cluster.postgres.version="$PREVIOUS_PATRONI_IMAGE_POSTGRES_VERSION" \
    --set cluster.configurations.observability.prometheusAutobind=true \
    --set configurations.objectstorage.create=false \
    --set-string cluster.configurations.backups.sgObjectStorage=backupconf \
    --set-string cluster.configurations.backups.cronSchedule='0 5 31 2 *' \
    --set cluster.configurations.backups.performance.maxDiskBandwidth=10485760 \
    --set cluster.configurations.backups.performance.maxNetworkBandwidth=5242880 \
    --set-string cluster.managedSql.scripts[0].script="CREATE DATABASE managed_sql;" \
    --set-string cluster.managedSql.scripts[1].scriptFrom.secretKeyRef.name=secret-script \
    --set-string cluster.managedSql.scripts[1].scriptFrom.secretKeyRef.key=script \
    --set-string cluster.managedSql.scripts[2].scriptFrom.configMapKeyRef.name=configmap-script \
    --set-string cluster.managedSql.scripts[2].scriptFrom.configMapKeyRef.key=script \
    --set-string cluster.initialData.restore.fromBackup.name="$BACKUP_NAME" \
    --set-string cluster.metadata.labels.clusterPods.pod-label="$RANDOM_VALUE" \
    --set-string cluster.metadata.annotations.clusterPods.pod-annotation="$RANDOM_VALUE" \
    --set-string cluster.metadata.annotations.primaryService.primary-service-label="$RANDOM_VALUE" \
    --set-string cluster.metadata.annotations.replicasService.replicas-service-label="$RANDOM_VALUE" \
    --set distributedLogs.enabled=true \
    --set distributedLogs.create=false \
    --set-string cluster.distributedLogs.sgDistributedLogs="$CLUSTER_NAMESPACE.$DISTRIBUTEDLOGS_NAME"

  wait_cluster "$CLUSTER_1_NAME" "$CLUSTER_NAMESPACE"
  wait_cluster "$DISTRIBUTEDLOGS_NAME" "$CLUSTER_NAMESPACE"

  generate_mock_data "$CLUSTER_1_NAME"

  PREVIOUS_PATRONI_1_CONFIG_PATH="$LOG_PATH/previous-patroni-1-config.json"
  kubectl get endpoints -n "$CLUSTER_NAMESPACE" "$CLUSTER_1_NAME-config" \
    --template '{{ .metadata.annotations.config }}' > "$PREVIOUS_PATRONI_1_CONFIG_PATH"
  PREVIOUS_PGBOUNCER_1_CONFIG_PATH="$LOG_PATH/previous-pgbouncer-1-config.ini"
  kubectl get configmap -n "$CLUSTER_NAMESPACE" "$CLUSTER_1_NAME-connection-pooling-config" \
    --template '{{ index .data "pgbouncer.ini" }}' > "$PREVIOUS_PGBOUNCER_1_CONFIG_PATH"
}

e2e_is_backup_phase() {
  [ "$(kubectl get sgbackup -n "$CLUSTER_NAMESPACE" "$BACKUP_NAME" -o=jsonpath='{.status.process.status}')" = "$1" ]
}

e2e_test_uninstall() {
  if ! can_install_operator_version "$STACKGRES_PREVIOUS_VERSION"
  then
    return
  fi

  uninstall_prometheus_operator
  delete_operator_only
  install_operator_only
  wait_pods_running "$OPERATOR_NAMESPACE" 2
}

e2e_test() {
  if ! can_install_operator_version "$STACKGRES_PREVIOUS_VERSION"
  then
    echo "Skip dbops-restart-after-upgrade since previous version of operator $STACKGRES_PREVIOUS_VERSION can not be installed"
    return
  fi
  run_test "Check clusters before operator upgrade" check_before_operator_upgrade
  run_test "Check that operator can be upgraded to newer version" check_operator_upgrade
  run_test "Check that cluster with 1 node can restart after operator upgrade with reduced impact" check_cluster_1_restart_start
  run_test "Check that cluster with 1 node can complete restart after operator upgrade with reduced impact" check_cluster_1_restart
  run_test "Checking that metrics are exported for cluster with 1 node" check_metrics "$CLUSTER_1_NAME"
  run_test "Check that the conversion webhooks are configured" check_conversion_webhooks_configured
}

check_before_operator_upgrade() {
  check_mock_data_samehost "$CLUSTER_1_NAME"

  local RESOURCE
  for RESOURCE in $(
    echo "sgcluster/$CLUSTER_1_NAME"
    )
  do
    if wait_until eval 'kubectl wait -n "$CLUSTER_NAMESPACE" "$RESOURCE" \
      --for condition=PendingRestart=false --timeout 0'
    then
      success "$RESOURCE is not pending restart after creation"
    else
      fail "$RESOURCE is pending restart after creation"
    fi
  done
}

check_operator_upgrade() {
  local POD_OPERATOR_IMAGE
  POD_OPERATOR_IMAGE="$(kubectl get pod -n "$OPERATOR_NAMESPACE" -l app=stackgres-operator \
    --template '{{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ range .spec.containers }}{{ printf "%s\n" .image }}{{ end }}{{ end }}{{ end }}' \
    | head -n 1 | grep '/operator:')"
  if ! printf %s "$POD_OPERATOR_IMAGE" | grep -q '^[^/]\+\.[^/]\+/'
  then
    POD_OPERATOR_IMAGE="docker.io/$POD_OPERATOR_IMAGE"
  fi
  if [ "${POD_OPERATOR_IMAGE#*/}" = "${STACKGRES_PREVIOUS_OPERATOR_IMAGE#*/}" ]
  then
    success "Operator pod is using the previous operator image"
  else
    echo "FAILURE. Operator pod is not using the previous operator image"
    echo
    echo "Expected previous operator image is $STACKGRES_PREVIOUS_OPERATOR_IMAGE"
    echo
    echo "Used previous operator image is $POD_OPERATOR_IMAGE"
    return 1
  fi
  local POD_RESTAPI_IMAGE
  POD_RESTAPI_IMAGE="$(kubectl get pod -n "$OPERATOR_NAMESPACE" -l "$(
    if [ "$STACKGRES_PREVIOUS_VERSION" = 1.5.0 ]
    then
      printf %s app=stackgres-restapi
    else
      printf %s app=StackGresConfig,stackgres.io/restapi=true
    fi
    )" \
    --template '{{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ range .spec.containers }}{{ printf "%s\n" .image }}{{ end }}{{ end }}{{ end }}' \
    | head -n 1)"
  if ! printf %s "$POD_RESTAPI_IMAGE" | grep -q '^[^/]\+\.[^/]\+/'
  then
    POD_RESTAPI_IMAGE="docker.io/$POD_RESTAPI_IMAGE"
  fi
  if [ "${POD_RESTAPI_IMAGE#*/}" = "${STACKGRES_PREVIOUS_RESTAPI_IMAGE#*/}" ]
  then
    success "Restapi pod is using the previous restapi image"
  else
    echo "FAILURE. Restapi pod is not using the previous restapi image"
    echo
    echo "Expected previous restapi image is $STACKGRES_PREVIOUS_RESTAPI_IMAGE"
    echo
    echo "Used previous restapi image is $POD_RESTAPI_IMAGE"
    return 1
  fi

  upgrade_operator --reset-values \
    --set grafana.autoEmbed=true \
    --set-string grafana.webHost="prometheus-grafana.$(prometheus_namespace)"

  timeout "$E2E_TIMEOUT" kubectl rollout status -n "$OPERATOR_NAMESPACE" "$(kubectl get deployment -n "$OPERATOR_NAMESPACE" -l app=stackgres-operator -o name)"
  POD_OPERATOR_IMAGE="$(kubectl get pod -n "$OPERATOR_NAMESPACE" -l app=stackgres-operator --sort-by '{.metadata.creationTimestamp}' \
    --template '{{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ range .spec.containers }}{{ printf "%s\n" .image }}{{ end }}{{ end }}{{ end }}' \
    | grep '/operator:' | tail -n 1 | grep .)"
  if ! printf %s "$POD_OPERATOR_IMAGE" | grep -q '^[^/]\+\.[^/]\+/'
  then
    POD_OPERATOR_IMAGE="docker.io/$POD_OPERATOR_IMAGE"
  fi
  if [ "${POD_OPERATOR_IMAGE#*/}" = "${STACKGRES_OPERATOR_IMAGE#*/}" ]
  then
    success "Operator pod is using the new operator image"
  else
    echo "FAILURE. Operator pod is not using the new operator image"
    echo
    echo "Expected new operator image is $STACKGRES_OPERATOR_IMAGE"
    echo
    echo "Used operator image is $POD_OPERATOR_IMAGE"
    return 1
  fi
  DEPLOYMENT_RESTAPI="$(wait_until eval 'kubectl get deployment -n "$OPERATOR_NAMESPACE" stackgres-restapi -o name | grep .')"
  timeout "$E2E_TIMEOUT" kubectl rollout status -n "$OPERATOR_NAMESPACE" "$DEPLOYMENT_RESTAPI"
  POD_RESTAPI_IMAGE="$(kubectl get pod -n "$OPERATOR_NAMESPACE" -l app=StackGresConfig,stackgres.io/restapi=true --sort-by '{.metadata.creationTimestamp}' \
    --template '{{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ range .spec.containers }}{{ printf "%s\n" .image }}{{ end }}{{ end }}{{ end }}' \
    | grep '/restapi:' | tail -n 1 | grep .)"
  if ! printf %s "$POD_RESTAPI_IMAGE" | grep -q '^[^/]\+\.[^/]\+/'
  then
    POD_RESTAPI_IMAGE="docker.io/$POD_RESTAPI_IMAGE"
  fi
  if [ "${POD_RESTAPI_IMAGE#*/}" = "${STACKGRES_RESTAPI_IMAGE#*/}" ]
  then
    success "Operator pod is using the new restapi image"
  else
    echo "FAILURE. Operator pod is not using the new restapi image"
    echo
    echo "Expected new restapi image is $STACKGRES_RESTAPI_IMAGE"
    echo
    echo "Used restapi image is $POD_RESTAPI_IMAGE"
    return 1
  fi
}

check_cluster_1_restart_start() {
  kubectl delete sgbackup -n "$CLUSTER_NAMESPACE" "$BACKUP_NAME"
  check_cluster_restart_start \
    "$CLUSTER_1_NAME" "$DBOPS_1_NAME" "ReducedImpact" \
    "$PREVIOUS_PATRONI_1_CONFIG_PATH" "$PREVIOUS_PGBOUNCER_1_CONFIG_PATH"
}

check_cluster_1_restart() {
  check_cluster_restart \
    "$CLUSTER_1_NAME" "$DBOPS_1_NAME" "ReducedImpact"
}

check_cluster_restart_start() {
  local CLUSTER_NAME="$1"
  local DBOPS_NAME="$2"
  local METHOD="$3"
  local PREVIOUS_PATRONI_CONFIG_PATH="$4"
  local PREVIOUS_PGBOUNCER_CONFIG_PATH="$5"
  shift 5

  check_mock_data_samehost "$CLUSTER_NAME"

  cat << EOF | kubectl create -f -
apiVersion: stackgres.io/v1
kind: SGDbOps
metadata:
  name: $DBOPS_NAME
  namespace: $CLUSTER_NAMESPACE
spec:
  sgCluster: $CLUSTER_NAME
  op: restart
  maxRetries: 3
  restart:
    method: $METHOD
EOF

  assert_dbops_running "$DBOPS_NAME" "$CLUSTER_NAMESPACE"

  wait_until eval '[ "$(kubectl get sgcluster -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" \
    --template "{{ if .metadata.annotations }}{{ if (index .metadata.annotations \"stackgres.io/lockTimeout\") }}{{ (index .metadata.annotations \"stackgres.io/lockTimeout\") }}{{ else }}0{{ end }}{{ else }}0{{ end }}")" != 0 ]'
  if kubectl patch sgcluster -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" --type json \
    -p '[{"op":"replace","path":"/spec/metadata","value":{"annotations":{"allResources":{"'"$(random_string)"'": "'"$(random_string)"'"}}}}]' \
    >/dev/null 2>&1
  then
    fail "Cluster has been updated while locked."
  else
    success "Cluster has not been updated while locked."
  fi
}

check_cluster_restart() {
  local CLUSTER_NAME="$1"
  local DBOPS_NAME="$2"
  local METHOD="$3"
  local PRIMARY_INSTANCE
  shift 3

  assert_dbops_completion "$DBOPS_NAME" "$CLUSTER_NAMESPACE" "$((E2E_TIMEOUT * 2))"

  check_cluster_after_restart

  PRIMARY_INSTANCE="$(kubectl get endpoints -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" \
    --template '{{ .metadata.annotations.leader }}')"
  PRIMARY_INSTANCE="${PRIMARY_INSTANCE#$CLUSTER_NAME-}"

  check_mock_data_samehost "$CLUSTER_NAME" "$PRIMARY_INSTANCE"
}

check_cluster_after_restart() {
  if wait_until eval 'kubectl wait "$CLUSTER_CRD" -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" \
    --for condition=PendingRestart=false --timeout 0'
  then
    success "Cluster $CLUSTER_NAME is not pending restart after restart"
  else
    fail "Cluster $CLUSTER_NAME is pending restart after restart"
  fi

  local STS_UPDATE_REVISION
  STS_UPDATE_REVISION="$(wait_until kubectl get sts -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" --template '{{ .status.updateRevision }}')"
  local POD_CONTROLLER_REVISION_HASH
  local POD_CONTROLLER_REVISION_HASHES
  POD_CONTROLLER_REVISION_HASHES="$(kubectl get pod -n "$CLUSTER_NAMESPACE" \
      -l "app=StackGresCluster,stackgres.io/cluster-name=$CLUSTER_NAME,stackgres.io/cluster=true" -o json \
    | jq ".items[]|select(.metadata.name | startswith(\"$CLUSTER_NAME\"))" \
    | jq -r '.metadata.labels."controller-revision-hash"')"

  for POD_CONTROLLER_REVISION_HASH in $POD_CONTROLLER_REVISION_HASHES
  do
    if [ "$POD_CONTROLLER_REVISION_HASH" != "$STS_UPDATE_REVISION" ]
    then
      echo "FAILURE. Cluster $CLUSTER_NAME restart did not updated sucesfully some pods"
      return 1
    fi
  done

  PODS="$(kubectl get pod -n "$CLUSTER_NAMESPACE" \
    -l "app=StackGresCluster,stackgres.io/cluster-name=$CLUSTER_NAME,stackgres.io/cluster=true" -o name \
    | cut -d / -f 2)"
  for POD in $PODS
  do
    POD_PATRONI_IMAGE="$(kubectl get pod -n "$CLUSTER_NAMESPACE" "$POD" \
      --template '{{ range .spec.containers }}{{ printf "%s\n" .image }}{{ end }}' \
       | head -n 1 | grep '/patroni\(-ext\)\?:')"
    if ! printf %s "$POD_PATRONI_IMAGE" | grep -q '^[^/]\+\.[^/]\+/'
    then
      POD_PATRONI_IMAGE="docker.io/$POD_PATRONI_IMAGE"
    fi
    if [ "$POD_PATRONI_IMAGE" = "$PATRONI_IMAGE" ]
    then
      success "Pod $POD is using the latest patroni image"
    else
      echo "FAILURE. Pod $POD is not using the latest patroni image"
      echo
      echo "New patroni images is '$PATRONI_IMAGE'"
      echo
      echo "Used patroni image is '$POD_PATRONI_IMAGE'"
      return 1
    fi
  done

  local PRIMARY_SERVICE_TYPE
  PRIMARY_SERVICE_TYPE="$(kubectl get service -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-primary" \
    --template '{{ .spec.type }}')"
  if [ "$PRIMARY_SERVICE_TYPE" = "ExternalName" ]
  then
    success "Cluster $CLUSTER_NAME primary service is of type ExternalName"
  else
    echo "FAILURE. Cluster $CLUSTER_NAME primary service is not of type ExternalName"
    return 1
  fi
}

check_conversion_webhooks_configured(){
  CONVERSTION_STRATEGY="$(kubectl get crd sgclusters.stackgres.io -o jsonpath='{.spec.conversion.strategy}')"

  assert_string_equal "Webhook" "$CONVERSTION_STRATEGY"

  CONVERSTION_STRATEGY="$(kubectl get crd sgdistributedlogs.stackgres.io -o jsonpath='{.spec.conversion.strategy}')"

  assert_string_equal "Webhook" "$CONVERSTION_STRATEGY"
}

check_sts_is_not_altered() {
  local TARGET_CLUSTER="$1"

  local STS_PATRONI_IMAGE
  STS_PATRONI_IMAGE="$(wait_until kubectl get sts -n "$CLUSTER_NAMESPACE" "$TARGET_CLUSTER" -o json \
    | jq -r '.spec.template.spec.containers[] | select(.name == "patroni") | .image')"

  if assert_string_equal "$PREVIOUS_PATRONI_IMAGE" "$STS_PATRONI_IMAGE"
  then
    success "StatefulSet $TARGET_CLUSTER is not being altered on operator upgrade"
  else 
    fail "StatefulSet $TARGET_CLUSTER is being altered on operator upgrade"
  fi
}
